{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["_9LvXKfjG7Ck","vKPkewxeDi42"],"mount_file_id":"1HmmM6ngo7SMZMncz7PW-fOr0eZrgXc09","authorship_tag":"ABX9TyP2M7PWsf6ULVI4x8yha7cE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["NB Classifier Weather\\\n","Libraries: sklearn\n","\n","Step1: Import necessary library\n","\n","Step2: Prepare dataset\n","\n","Step3: Digitize the dataset using encoding\n","\n","Step4: Merge different features to prepare dataset\n","\n","Step5: Train Naive Bayes Classifier\n","\n","Step6: Predict output for new data\n","\n","https://www.tutorialspoint.com/scikit_learn/scikit_learn_multinomial_naive_bayes.htm\n","\n","# **1_NB_Classifier_Weather**"],"metadata":{"id":"sQoGMfXC35KN"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","from sklearn.naive_bayes import GaussianNB , MultinomialNB "],"metadata":{"id":"e-EHgbrF4CNj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Prepare dataset\n","weather = ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy','Rainy', 'Overcast','Sunny', 'Sunny', 'Rainy', 'Sunny', 'Overcast', 'Overcast', 'Rainy']\n","temp = ['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n","play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']"],"metadata":{"id":"HuJO5lAj5Q9l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Digitize the dataset using encoding.\n","#Create labelEncoder -----> check onehot encoding\n","le=preprocessing.LabelEncoder()\n","\n","#convert string labels into numbers.\n","weather_encoded = le.fit_transform(weather)\n","temp_encoded = le.fit_transform(temp)\n","label_encoded = le.fit_transform(play)\n","\n"],"metadata":{"id":"brW2ZB8_5t_k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#print encoded data\n","print(\"Weather: \", weather_encoded)\n","print(\"Temperature: \", temp_encoded)\n","print(\"Play class label: \", label_encoded)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z9veKpWT_bLN","executionInfo":{"status":"ok","timestamp":1677077477057,"user_tz":-330,"elapsed":63,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"2369fd03-b991-4bf7-d5f8-f09b0b88236f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Weather:  [2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n","Temperature:  [1 1 1 2 0 0 0 2 0 2 2 2 1 2]\n","Play class label:  [0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n"]}]},{"cell_type":"code","source":["#Merge different features to prepare dataset\n","\n","#combining weather and temp into single listof tuples\n","features = tuple(zip(weather_encoded, temp_encoded))"],"metadata":{"id":"MnQqfKmN_04L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Print merged feature\n","print(\"Features: \", features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hG6aCBlUAiyz","executionInfo":{"status":"ok","timestamp":1677077477058,"user_tz":-330,"elapsed":52,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"70527497-5043-4cbf-abac-ee1ef142c92c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Features:  ((2, 1), (2, 1), (0, 1), (1, 2), (1, 0), (1, 0), (0, 0), (2, 2), (2, 0), (1, 2), (2, 2), (0, 2), (0, 1), (1, 2))\n"]}]},{"cell_type":"code","source":["#Train Naive Bayes Classifier\n","#create a classifier\n","model = MultinomialNB()"],"metadata":{"id":"FwOBAM-XA1yc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Train the model using training dataset\n","model.fit(features,label_encoded)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R6-lYO2ZBLs8","executionInfo":{"status":"ok","timestamp":1677077477059,"user_tz":-330,"elapsed":50,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"2da546dd-63e6-4a6f-e067-89321cd2b8b0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultinomialNB()"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["#Predict output for new data\n","predicted = model.predict([[0,2]]) # 0->overcast 1->mild\n","print(\"Predicted value for (overcast,mild) \",predicted)\n","predicted = model.predict([[0,1]])\n","print(\"Predicted value for (overcast,hot) \",predicted)\n","predicted = model.predict([[2,2]])\n","print(\"Predicted value for (sunny,mild) \",predicted)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l0mm4eOwD0Rs","executionInfo":{"status":"ok","timestamp":1677077477060,"user_tz":-330,"elapsed":49,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"bcd505aa-0488-4aa9-bd73-5c4da5c4b47d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted value for (overcast,mild)  [1]\n","Predicted value for (overcast,hot)  [1]\n","Predicted value for (sunny,mild)  [1]\n"]}]},{"cell_type":"markdown","source":["# **pdf 3_2 Exercise 3 questions 1 and 2**"],"metadata":{"id":"WRSL2GgT_Nn4"}},{"cell_type":"code","source":["#What will be the value of Play, if Outlook is ’Rainy’, Temperature is ’Mild’, Humidity =’Nor-\n","#mal’, and Wind = ’False’?\n","from sklearn import preprocessing\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB\n","from google.colab import drive\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pandas as pd\n","dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Dataset/Naive Bayes/Dataset1.csv')\n","one_hot = pd.get_dummies(dataset, columns=['Outlook','Temp','Humidity','Wind','Play'])\n","print(one_hot)\n","#extract feature and label\n","#In pandas, the axis parameter specifies the dimension of the DataFrame or Series that you want to operate on.\n","##In particular, axis=1 refers to the columns of a DataFrame, while axis=0 refers to the rows of a DataFrame.\n","#When you call the drop method on a DataFrame with axis=1, it means you want to drop one or more columns\n","# from the DataFrame.\n","features = one_hot.drop(['Play_N', 'Play_Y'], axis=1)\n","label = one_hot[['Play_N','Play_Y']].values[:, 0]\n","model = MultinomialNB()\n","model.fit(features, label)\n","\n","\n","#predict value\n","new_data = pd.DataFrame({\n","    'Outlook_O': [0],\n","    'Outlook_R': [1],\n","    'Outlook_S': [0],\n","    'Temp_C': [0],\n","    'Temp_H': [1],\n","    'Temp_M': [0],\n","    'Humidity_High': [0],\n","    'Humidity_Low': [0],\n","    'Humidity_Normal':[1],\n","    'Wind_F': [1],\n","    'Wind_T': [0]\n","})\n","predicted = model.predict(new_data)\n","print('predicted is ',predicted)\n","print('Probability', model.predict_proba(new_data))\n","\n","#What will be the value of Play, if Outlook is ’Sunny’, Temeprature is ’Cool’, Humidity =’High’,\n","#and Wind = ’True’?\n","new_data = pd.DataFrame({\n","    'Outlook_O': [0],\n","    'Outlook_R': [0],\n","    'Outlook_S': [1],\n","    'Temp_C': [1],\n","    'Temp_H': [0],\n","    'Temp_M': [0],\n","    'Humidity_High': [1],\n","    'Humidity_Low': [0],\n","    'Humidity_Normal':[0],\n","    'Wind_F': [0],\n","    'Wind_T': [1]\n","})\n","predicted = model.predict(new_data)\n","print('predicted is ',predicted)\n","print('Probability', model.predict_proba(new_data))\n","\n","\n","#for model accuracy split data into train and test set\n","data_train, data_test, target_train, target_test = train_test_split(features,label,test_size = 0.2 , random_state=42)\n","model.fit(data_train,target_train)\n","pred = model.predict(data_test)\n","accuracy = accuracy_score(target_test, pred)\n","print(\"Accuracy:\", accuracy)\n","\n","\n","precision = precision_score(target_test, pred)\n","recall = recall_score(target_test, pred)\n","\n","\n","print('precision: {}'.format(precision))\n","print('recall: {}'.format(recall))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bz9rPy3V-qWs","executionInfo":{"status":"ok","timestamp":1677089246589,"user_tz":-330,"elapsed":45,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"bd7b50ce-b73c-4e9a-b3c2-45f8c6bbf837"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["    Outlook_O  Outlook_R  Outlook_S  Temp_C  Temp_H  Temp_M  Humidity_High  \\\n","0           0          1          0       0       1       0              0   \n","1           0          1          0       0       1       0              1   \n","2           1          0          0       0       1       0              0   \n","3           0          0          1       0       0       1              0   \n","4           0          0          1       1       0       0              0   \n","5           0          0          1       1       0       0              0   \n","6           1          0          0       1       0       0              0   \n","7           0          1          0       0       0       1              0   \n","8           0          1          0       1       0       0              0   \n","9           0          0          1       0       0       1              1   \n","10          0          1          0       0       0       1              1   \n","11          1          0          0       0       0       1              0   \n","12          1          0          0       0       1       0              0   \n","13          0          0          1       0       0       1              0   \n","\n","    Humidity_Low  Humidity_Normal  Wind_F  Wind_T  Play_N  Play_Y  \n","0              0                1       1       0       1       0  \n","1              0                0       0       1       1       0  \n","2              0                1       1       0       0       1  \n","3              0                1       1       0       0       1  \n","4              0                1       1       0       0       1  \n","5              1                0       0       1       1       0  \n","6              0                1       0       1       0       1  \n","7              0                1       1       0       1       0  \n","8              1                0       1       0       0       1  \n","9              0                0       1       0       0       1  \n","10             0                0       0       1       0       1  \n","11             1                0       0       1       0       1  \n","12             0                1       1       0       0       1  \n","13             0                1       0       1       1       0  \n","predicted is  [1]\n","Probability [[0.47208555 0.52791445]]\n","predicted is  [0]\n","Probability [[0.57674843 0.42325157]]\n","Accuracy: 0.6666666666666666\n","precision: 0.0\n","recall: 0.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["This warning message indicates that precision could not be computed because there were no predicted samples in one or more of the classes. This can happen when the model is not able to predict any samples for a particular class, either because there are no samples of that class in the test set or because the model is not able to distinguish between that class and others.\n","\n","To address this warning, you can set the zero_division parameter to a non-zero value when calling the precision function. This parameter determines the value to use for precision when there are no predicted samples in a class. For example, you could set zero_division=1 to treat precision as 1.0 when there are no predicted samples in a class. However, keep in mind that this may not be a meaningful value if there are actually samples of that class in the test set. Alternatively, you can try adjusting the model or the data to improve its ability to distinguish between classes."],"metadata":{"id":"2wF0jKbKRpIW"}},{"cell_type":"markdown","source":["# **2_NB_Classifier_Iris_2Classes**"],"metadata":{"id":"_9LvXKfjG7Ck"}},{"cell_type":"markdown","source":["Iris Dataset is a part of sklearn library. Sklearn comes loaded with datasets to practice machine learning techniques and iris is one of them. Iris has 4 numerical features and a tri class target variable. This dataset can be used for classification as well as clustering.\n","\n","Iris dataset contains five columns such as Petal Length, Petal Width, Sepal Length, Sepal Width and Species Type. Iris is a flowering plant"],"metadata":{"id":"NrQzBXJTKXWt"}},{"cell_type":"code","source":["#import scikit-learn library\n","import numpy as np\n","from sklearn import datasets\n","from sklearn.naive_bayes import GaussianNB"],"metadata":{"id":"QcFSvuLRHBvt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Load datasets\n","iris = datasets.load_iris()"],"metadata":{"id":"Pi9UYk4sHds9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Print the name of the features\n","print(\"Features :\",iris.feature_names)"],"metadata":{"id":"Ha_iJzrWKsWM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Print the class label type\n","print(\"Labels : \", iris.target_names)"],"metadata":{"id":"KuJX0kT7LNWd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The shape of the dataset means to print the total number of rows or entries and the total number of columns or features of that particular dataset."],"metadata":{"id":"kABFbNRZMV-1"}},{"cell_type":"code","source":["#print data(feature) shape:\n","print(\"DataShape: \", iris.data.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-YrZQ6YKLrMd","executionInfo":{"status":"ok","timestamp":1677077477064,"user_tz":-330,"elapsed":47,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"0d9745d2-45c9-4488-b6ad-45f300bc5754"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DataShape:  (150, 4)\n"]}]},{"cell_type":"code","source":["#print target shape\n","print(\"Target shape: \", iris.target.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GbNj8mFUMYNd","executionInfo":{"status":"ok","timestamp":1677077477065,"user_tz":-330,"elapsed":46,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"57dc7e4f-f8e8-49df-f5cd-2c6d9666b4fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Target shape:  (150,)\n"]}]},{"cell_type":"code","source":["#Print data\n","print(\"Data\", iris.data)"],"metadata":{"id":"062yVD7TMwRk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Print target \n","print(\"Target: \", iris.target)"],"metadata":{"id":"arEOpoufM_oF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["newdata = iris.data[50:,:]\n","newtarget = iris.target[50:]"],"metadata":{"id":"-ZvYXA4ZXcMD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print data(feature)shape\n","print(\"\\nNew Data shape: \",newdata.shape)\n","#print data(target)shape\n","print(\"\\nNew Target shape: \",newtarget.shape)"],"metadata":{"id":"gqGF-ga-e6jG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The train_test_split function randomly splits the data into two sets: X_train and X_test. We specified the test_size parameter to be 0.3, which means that 30% of the data will be used for the test set, and 70% of the data will be used for the training set.\n","\n","Now, suppose we want to split the data again, but this time using a different random state. We can set the random state to a different value, like 123.\n","\n","By setting the random state, we can ensure that the same random split is generated every time we run the code. This can be useful for testing and comparing different models, as we can ensure that the same data is used every time we train and test the model."],"metadata":{"id":"GKSm_Ms1-vfq"}},{"cell_type":"code","source":["#import the necessary module\n","from sklearn.model_selection import train_test_split\n","#split data set into train and test sets\n","data_train, data_test, target_train, target_test = train_test_split(newdata,\n","newtarget, test_size = 0.30, random_state = 5)"],"metadata":{"id":"FCtJaI2Nvtxt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","gnb = GaussianNB()\n","#train the model using training sets.\n","gnb.fit(data_train,target_train)\n","\n","#predict the response for test dataset\n","target_pred = gnb.predict(data_test)"],"metadata":{"id":"uK8U0_up_osj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Import scikit-learn metrics module for accuracy calculation\n","from sklearn import metrics\n","\n","#model accuracy, how often s the classifier correct?\n","print(\"Accuracy:\", metrics.accuracy_score(target_test,target_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HrJacBVHAuaR","executionInfo":{"status":"ok","timestamp":1677077477069,"user_tz":-330,"elapsed":40,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"ade2d9a2-6e97-44fe-b930-dc1b4da12c49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9\n"]}]},{"cell_type":"code","source":["#Import confusion_matrix from scikit-learn metrics module for confusion_matrix\n","from sklearn.metrics import confusion_matrix\n","confusion_matrix(target_test, target_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rlQqU3bMCkvC","executionInfo":{"status":"ok","timestamp":1677077477069,"user_tz":-330,"elapsed":37,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"9a3fb60a-3a5f-4e2a-a638-57b509061b43"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[16,  1],\n","       [ 2, 11]])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","precision = precision_score(target_test, target_pred)\n","recall = recall_score(target_test, target_pred)\n","print('precision: {}'.format(precision))\n","print('recall: {}'.format(recall))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"utPkPGeqC3_u","executionInfo":{"status":"ok","timestamp":1677077477070,"user_tz":-330,"elapsed":36,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"e469aa54-58d1-40df-adbc-60dcd50cd51b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["precision: 0.8888888888888888\n","recall: 0.9411764705882353\n"]}]},{"cell_type":"markdown","source":["# 3_NB_Classifier_Iris_3Classes"],"metadata":{"id":"vKPkewxeDi42"}},{"cell_type":"code","source":["#Import scikit-learn dataset library\n","from sklearn import datasets\n","from sklearn.naive_bayes import GaussianNB\n","#Load dataset\n","iris = datasets.load_iris()"],"metadata":{"id":"jyGRSP59D5C6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print the names of the 13 features\n","print(\"Features: \", iris.feature_names)\n","# print the label type of wine(class_0, class_1, class_2)\n","print(\"Labels: \", iris.target_names)\n","# print data(feature)shape\n","iris.data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e_bjLR27EExe","executionInfo":{"status":"ok","timestamp":1677077477072,"user_tz":-330,"elapsed":35,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"52e37544-3c8d-47a5-a66e-7db4895d4208"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Features:  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n","Labels:  ['setosa' 'versicolor' 'virginica']\n"]},{"output_type":"execute_result","data":{"text/plain":["(150, 4)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["#import the necessary module\n","from sklearn.model_selection import train_test_split\n","#split data set into train and test sets\n","data_train, data_test, target_train, target_test = train_test_split(iris.data,\n","iris.target, test_size = 0.30, random_state = 10)"],"metadata":{"id":"bv2E97ZNESYi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Suppose we have a small dataset of 10 numbers: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. We want to randomly split this dataset into two sets: a training set and a test set. We can use the train_test_split function from scikit-learn library to do this.\n","\n","The train_test_split function randomly splits the data into two sets: X_train and X_test. We specified the test_size parameter to be 0.3, which means that 30% of the data will be used for the test set, and 70% of the data will be used for the training set.\n","\n","Now, suppose we want to split the data again, but this time using a different random state. We can set the random state to a different value, like 123."],"metadata":{"id":"3Ansr0HSzixo"}},{"cell_type":"code","source":["import numpy as np\n","gnb = GaussianNB()\n","#Train the model using the training sets\n","gnb.fit(data_train, target_train)\n","#Predict the response for test dataset\n","target_pred = gnb.predict(data_test)\n","target_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjaEhJA2zG_K","executionInfo":{"status":"ok","timestamp":1677077477074,"user_tz":-330,"elapsed":34,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"a8240279-8239-4476-ea9c-4d16c2f0d8b1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 2, 0, 1, 0, 1, 1, 1, 0, 1, 1, 2, 1, 0, 0, 2, 1, 0, 0, 0, 2, 2,\n","       2, 0, 1, 0, 1, 1, 1, 2, 1, 1, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 1, 0,\n","       1])"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["#Import scikit-learn metrics module for accuracy calculation\n","from sklearn import metrics\n","# Model Accuracy, how often is the classifier correct?\n","print(\"Accuracy:\",metrics.accuracy_score(target_test, target_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vx2pHTgq0bAy","executionInfo":{"status":"ok","timestamp":1677077477074,"user_tz":-330,"elapsed":33,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"6225ca39-58b0-49c4-9214-951154abbdb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 1.0\n"]}]},{"cell_type":"code","source":["#Import confusion_matrix from scikit-learn metrics module for confusion_matrix\n","from sklearn.metrics import confusion_matrix\n","confusion_matrix(target_test, target_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TQqTvsoc1Mt6","executionInfo":{"status":"ok","timestamp":1677077477075,"user_tz":-330,"elapsed":33,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"7123a3e2-3f74-499f-b28e-9d3502a229cf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[14,  0,  0],\n","       [ 0, 17,  0],\n","       [ 0,  0, 14]])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","precision = precision_score(target_test, target_pred, average=None)\n","recall = recall_score(target_test, target_pred, average=None)\n","print('precision: {}'.format(precision))\n","print('recall: {}'.format(recall))"],"metadata":{"id":"o2fEy3kx1QOy","executionInfo":{"status":"ok","timestamp":1677077477076,"user_tz":-330,"elapsed":34,"user":{"displayName":"CE024_ Krishna_Chapla","userId":"10798977818354809234"}},"outputId":"37ebb341-761f-4991-edbb-536f0011d645","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["precision: [1. 1. 1.]\n","recall: [1. 1. 1.]\n"]}]},{"cell_type":"markdown","source":["# Exercise\n","1 <= Rollnumber <= 25: #Task 1: Try the algo on Dataset1 - OneHotEncoding of features:\n","and Train test Division 70%-30%\n","\n","Task 2: Apply algorithm on digits dataset - LabelEncoding of features: and Train test Divi-\n","sion 80% − 20%"],"metadata":{"id":"ETTqcHxhjBwA"}},{"cell_type":"code","source":["#import libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn import preprocessing\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB"],"metadata":{"id":"97RD1ISmjIsN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#prepare dataset\n","from google.colab import drive\n","dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Dataset/Naive Bayes/Dataset1.csv')\n","print(\"Data :- \\n\",dataset)\n","print(\"Data Statistics :- \\n\",dataset.describe())"],"metadata":{"id":"kMfECXKklKJI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["One hot encoding is a process of representing categorical variables as binary vectors, where each vector has a dimension equal to the number of possible categories. In this representation, each category is assigned a unique binary code, where all dimensions of the binary vector are 0, except for the one corresponding to the category, which is set to 1.\n","\n","For example, suppose we have a categorical variable called color with three possible categories: \"red\", \"green\", and \"blue\". One hot encoding would transform this variable into three binary vectors:\n","\n","\n","red:   [1, 0, 0]\n","green: [0, 1, 0]\n","blue:  [0, 0, 1]\n"],"metadata":{"id":"xW0rMRZ-sBuA"}},{"cell_type":"code","source":["one_hot = pd.get_dummies(dataset, columns=['Outlook','Temp','Humidity','Wind','Play'])\n","one_hot"],"metadata":{"id":"_vkeH9oinwya"},"execution_count":null,"outputs":[]}]}